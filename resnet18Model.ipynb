{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slLRPoZ_CYoe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "from tqdm import tqdm\n",
        "from torchsummary import summary\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "\n",
        "import torch.nn.init as init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCGdNqBHOhwG"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0 \n",
        "start_epoch = 0 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ow4hgZCOtTG",
        "outputId": "e797633d-e98f-40fe-dd11-6663c38ff34f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n"
          ]
        }
      ],
      "source": [
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyWtUJVBOxXu",
        "outputId": "91ab6c00-d818-4867-eb2b-f3f90fd886fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=50, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8x6i4-4PI1x"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKmWlKQKPLH9"
      },
      "outputs": [],
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywUUVi_sPQoU"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJC1EftvPU5w"
      },
      "outputs": [],
      "source": [
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 1, 1, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRwakegLO2iv",
        "outputId": "446aa7ef-7ba4-4d75-a168-ca8e0d92c6fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Building model..\n"
          ]
        }
      ],
      "source": [
        "print('==> Building model..')\n",
        "net = ResNet18()\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpTLI-WUP_tL"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8iWSWPdQBVn",
        "outputId": "7eb44241-40f3-4871-aa23-07f59246f7b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4977226\n"
          ]
        }
      ],
      "source": [
        "print(count_parameters(net))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRHgs5cqUhZc",
        "outputId": "30f9158e-5cea-49d6-f505-2c17f261e141"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
            "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
            "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
            "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
            "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
            "           Conv2d-13          [-1, 128, 16, 16]          73,728\n",
            "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
            "           Conv2d-15          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
            "           Conv2d-17          [-1, 128, 16, 16]           8,192\n",
            "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
            "       BasicBlock-19          [-1, 128, 16, 16]               0\n",
            "           Conv2d-20            [-1, 256, 8, 8]         294,912\n",
            "      BatchNorm2d-21            [-1, 256, 8, 8]             512\n",
            "           Conv2d-22            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-23            [-1, 256, 8, 8]             512\n",
            "           Conv2d-24            [-1, 256, 8, 8]          32,768\n",
            "      BatchNorm2d-25            [-1, 256, 8, 8]             512\n",
            "       BasicBlock-26            [-1, 256, 8, 8]               0\n",
            "           Conv2d-27            [-1, 512, 4, 4]       1,179,648\n",
            "      BatchNorm2d-28            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-29            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-30            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-31            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "       BasicBlock-33            [-1, 512, 4, 4]               0\n",
            "           Linear-34                   [-1, 10]           5,130\n",
            "           ResNet-35                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 4,977,226\n",
            "Trainable params: 4,977,226\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 9.06\n",
            "Params size (MB): 18.99\n",
            "Estimated Total Size (MB): 28.06\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "summary(net, (3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzjAlhDpO8L2"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adagrad(net.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTrtEKSFO-Xo"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with tqdm(trainloader, unit=\"batch\") as tepoch:\n",
        "      for batch_idx, (inputs, targets) in enumerate(tepoch):\n",
        "        tepoch.set_description(f\"Epoch {epoch} Training\")\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        tepoch.set_postfix(loss=(train_loss/(batch_idx+1)), accuracy=100.*correct/total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dw1iBHIPA9f"
      },
      "outputs": [],
      "source": [
        "def test(epoch):\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "      with tqdm(testloader, unit=\"batch\") as tepoch:\n",
        "        for batch_idx, (inputs, targets) in enumerate(tepoch):\n",
        "            tepoch.set_description(f\"Epoch {epoch} Testing\")\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            tepoch.set_postfix(loss=(test_loss/(batch_idx+1)), accuracy=100.*correct/total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl_0Fow4PCjJ",
        "outputId": "57d6e95c-a554-4123-e8c4-8bb768d4fc9a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 0 Training: 100%|██████████| 391/391 [00:40<00:00,  9.69batch/s, accuracy=49.8, loss=1.37]\n",
            "Epoch 0 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.27batch/s, accuracy=57.4, loss=1.25]\n",
            "Epoch 1 Training: 100%|██████████| 391/391 [00:32<00:00, 12.13batch/s, accuracy=66.1, loss=0.954]\n",
            "Epoch 1 Testing: 100%|██████████| 100/100 [00:04<00:00, 22.15batch/s, accuracy=66.3, loss=0.98]\n",
            "Epoch 2 Training: 100%|██████████| 391/391 [00:32<00:00, 11.87batch/s, accuracy=72.4, loss=0.786]\n",
            "Epoch 2 Testing: 100%|██████████| 100/100 [00:04<00:00, 21.45batch/s, accuracy=68.9, loss=0.896]\n",
            "Epoch 3 Training: 100%|██████████| 391/391 [00:32<00:00, 11.89batch/s, accuracy=76.3, loss=0.679]\n",
            "Epoch 3 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.81batch/s, accuracy=70, loss=0.993]\n",
            "Epoch 4 Training: 100%|██████████| 391/391 [00:33<00:00, 11.73batch/s, accuracy=79.3, loss=0.602]\n",
            "Epoch 4 Testing: 100%|██████████| 100/100 [00:03<00:00, 28.53batch/s, accuracy=78.1, loss=0.65]\n",
            "Epoch 5 Training: 100%|██████████| 391/391 [00:33<00:00, 11.81batch/s, accuracy=81.2, loss=0.551]\n",
            "Epoch 5 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.93batch/s, accuracy=78.9, loss=0.646]\n",
            "Epoch 6 Training: 100%|██████████| 391/391 [00:33<00:00, 11.71batch/s, accuracy=82.4, loss=0.513]\n",
            "Epoch 6 Testing: 100%|██████████| 100/100 [00:03<00:00, 28.34batch/s, accuracy=76.6, loss=0.733]\n",
            "Epoch 7 Training: 100%|██████████| 391/391 [00:32<00:00, 11.86batch/s, accuracy=83.7, loss=0.474]\n",
            "Epoch 7 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.03batch/s, accuracy=80.6, loss=0.585]\n",
            "Epoch 8 Training: 100%|██████████| 391/391 [00:32<00:00, 11.91batch/s, accuracy=84.5, loss=0.453]\n",
            "Epoch 8 Testing: 100%|██████████| 100/100 [00:04<00:00, 21.76batch/s, accuracy=80.2, loss=0.583]\n",
            "Epoch 9 Training: 100%|██████████| 391/391 [00:32<00:00, 11.98batch/s, accuracy=85.5, loss=0.424]\n",
            "Epoch 9 Testing: 100%|██████████| 100/100 [00:04<00:00, 22.37batch/s, accuracy=84.2, loss=0.489]\n",
            "Epoch 10 Training: 100%|██████████| 391/391 [00:32<00:00, 11.98batch/s, accuracy=86.3, loss=0.405]\n",
            "Epoch 10 Testing: 100%|██████████| 100/100 [00:03<00:00, 28.33batch/s, accuracy=82.3, loss=0.527]\n",
            "Epoch 11 Training: 100%|██████████| 391/391 [00:33<00:00, 11.85batch/s, accuracy=86.8, loss=0.389]\n",
            "Epoch 11 Testing: 100%|██████████| 100/100 [00:03<00:00, 29.01batch/s, accuracy=84.9, loss=0.437]\n",
            "Epoch 12 Training: 100%|██████████| 391/391 [00:32<00:00, 11.90batch/s, accuracy=87.3, loss=0.375]\n",
            "Epoch 12 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.36batch/s, accuracy=84.4, loss=0.451]\n",
            "Epoch 13 Training: 100%|██████████| 391/391 [00:32<00:00, 11.95batch/s, accuracy=87.5, loss=0.362]\n",
            "Epoch 13 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.14batch/s, accuracy=85.7, loss=0.447]\n",
            "Epoch 14 Training: 100%|██████████| 391/391 [00:32<00:00, 12.09batch/s, accuracy=87.9, loss=0.353]\n",
            "Epoch 14 Testing: 100%|██████████| 100/100 [00:04<00:00, 21.93batch/s, accuracy=84.6, loss=0.477]\n",
            "Epoch 15 Training: 100%|██████████| 391/391 [00:32<00:00, 12.10batch/s, accuracy=88.3, loss=0.34]\n",
            "Epoch 15 Testing: 100%|██████████| 100/100 [00:04<00:00, 24.43batch/s, accuracy=84.3, loss=0.486]\n",
            "Epoch 16 Training: 100%|██████████| 391/391 [00:32<00:00, 12.07batch/s, accuracy=88.7, loss=0.332]\n",
            "Epoch 16 Testing: 100%|██████████| 100/100 [00:03<00:00, 28.70batch/s, accuracy=83.8, loss=0.493]\n",
            "Epoch 17 Training: 100%|██████████| 391/391 [00:32<00:00, 11.91batch/s, accuracy=88.9, loss=0.321]\n",
            "Epoch 17 Testing: 100%|██████████| 100/100 [00:03<00:00, 28.15batch/s, accuracy=86.4, loss=0.416]\n",
            "Epoch 18 Training: 100%|██████████| 391/391 [00:32<00:00, 11.97batch/s, accuracy=89.1, loss=0.315]\n",
            "Epoch 18 Testing: 100%|██████████| 100/100 [00:03<00:00, 28.91batch/s, accuracy=86.4, loss=0.406]\n",
            "Epoch 19 Training: 100%|██████████| 391/391 [00:32<00:00, 12.12batch/s, accuracy=89.5, loss=0.308]\n",
            "Epoch 19 Testing: 100%|██████████| 100/100 [00:04<00:00, 21.82batch/s, accuracy=86.4, loss=0.424]\n",
            "Epoch 20 Training: 100%|██████████| 391/391 [00:31<00:00, 12.22batch/s, accuracy=89.5, loss=0.306]\n",
            "Epoch 20 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.36batch/s, accuracy=86.3, loss=0.423]\n",
            "Epoch 21 Training: 100%|██████████| 391/391 [00:32<00:00, 11.97batch/s, accuracy=89.9, loss=0.298]\n",
            "Epoch 21 Testing: 100%|██████████| 100/100 [00:03<00:00, 28.65batch/s, accuracy=83, loss=0.552]\n",
            "Epoch 22 Training: 100%|██████████| 391/391 [00:32<00:00, 11.95batch/s, accuracy=89.9, loss=0.298]\n",
            "Epoch 22 Testing: 100%|██████████| 100/100 [00:03<00:00, 28.59batch/s, accuracy=86.8, loss=0.402]\n",
            "Epoch 23 Training: 100%|██████████| 391/391 [00:32<00:00, 12.04batch/s, accuracy=90.3, loss=0.287]\n",
            "Epoch 23 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.66batch/s, accuracy=87.1, loss=0.396]\n",
            "Epoch 24 Training: 100%|██████████| 391/391 [00:32<00:00, 12.14batch/s, accuracy=90.3, loss=0.285]\n",
            "Epoch 24 Testing: 100%|██████████| 100/100 [00:04<00:00, 22.56batch/s, accuracy=88.2, loss=0.363]\n",
            "Epoch 25 Training: 100%|██████████| 391/391 [00:32<00:00, 12.19batch/s, accuracy=90.4, loss=0.282]\n",
            "Epoch 25 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.49batch/s, accuracy=87.2, loss=0.395]\n",
            "Epoch 26 Training: 100%|██████████| 391/391 [00:32<00:00, 11.98batch/s, accuracy=90.4, loss=0.281]\n",
            "Epoch 26 Testing: 100%|██████████| 100/100 [00:03<00:00, 28.62batch/s, accuracy=86.8, loss=0.416]\n",
            "Epoch 27 Training: 100%|██████████| 391/391 [00:33<00:00, 11.83batch/s, accuracy=90.6, loss=0.272]\n",
            "Epoch 27 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.10batch/s, accuracy=87.8, loss=0.394]\n",
            "Epoch 28 Training: 100%|██████████| 391/391 [00:32<00:00, 11.99batch/s, accuracy=90.8, loss=0.266]\n",
            "Epoch 28 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.73batch/s, accuracy=87.1, loss=0.415]\n",
            "Epoch 29 Training: 100%|██████████| 391/391 [00:32<00:00, 12.15batch/s, accuracy=90.8, loss=0.267]\n",
            "Epoch 29 Testing: 100%|██████████| 100/100 [00:04<00:00, 21.42batch/s, accuracy=86.9, loss=0.427]\n",
            "Epoch 30 Training: 100%|██████████| 391/391 [00:32<00:00, 12.02batch/s, accuracy=91, loss=0.264]\n",
            "Epoch 30 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.02batch/s, accuracy=87.2, loss=0.413]\n",
            "Epoch 31 Training: 100%|██████████| 391/391 [00:33<00:00, 11.77batch/s, accuracy=90.9, loss=0.264]\n",
            "Epoch 31 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.81batch/s, accuracy=88.7, loss=0.354]\n",
            "Epoch 32 Training: 100%|██████████| 391/391 [00:32<00:00, 11.89batch/s, accuracy=91.4, loss=0.252]\n",
            "Epoch 32 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.86batch/s, accuracy=87.5, loss=0.397]\n",
            "Epoch 33 Training: 100%|██████████| 391/391 [00:32<00:00, 11.86batch/s, accuracy=91.4, loss=0.254]\n",
            "Epoch 33 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.93batch/s, accuracy=88.5, loss=0.363]\n",
            "Epoch 34 Training: 100%|██████████| 391/391 [00:32<00:00, 12.05batch/s, accuracy=91.5, loss=0.249]\n",
            "Epoch 34 Testing: 100%|██████████| 100/100 [00:04<00:00, 22.79batch/s, accuracy=87.5, loss=0.376]\n",
            "Epoch 35 Training: 100%|██████████| 391/391 [00:32<00:00, 11.93batch/s, accuracy=91.6, loss=0.245]\n",
            "Epoch 35 Testing: 100%|██████████| 100/100 [00:04<00:00, 23.16batch/s, accuracy=87.8, loss=0.375]\n",
            "Epoch 36 Training: 100%|██████████| 391/391 [00:32<00:00, 11.85batch/s, accuracy=91.4, loss=0.249]\n",
            "Epoch 36 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.10batch/s, accuracy=87.8, loss=0.398]\n",
            "Epoch 37 Training: 100%|██████████| 391/391 [00:33<00:00, 11.65batch/s, accuracy=91.6, loss=0.243]\n",
            "Epoch 37 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.57batch/s, accuracy=87.4, loss=0.39]\n",
            "Epoch 38 Training: 100%|██████████| 391/391 [00:33<00:00, 11.69batch/s, accuracy=91.6, loss=0.246]\n",
            "Epoch 38 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.46batch/s, accuracy=88.5, loss=0.357]\n",
            "Epoch 39 Training: 100%|██████████| 391/391 [00:33<00:00, 11.83batch/s, accuracy=91.7, loss=0.237]\n",
            "Epoch 39 Testing: 100%|██████████| 100/100 [00:04<00:00, 24.68batch/s, accuracy=87.5, loss=0.389]\n",
            "Epoch 40 Training: 100%|██████████| 391/391 [00:32<00:00, 11.87batch/s, accuracy=91.6, loss=0.239]\n",
            "Epoch 40 Testing: 100%|██████████| 100/100 [00:04<00:00, 21.14batch/s, accuracy=88.1, loss=0.367]\n",
            "Epoch 41 Training: 100%|██████████| 391/391 [00:32<00:00, 11.95batch/s, accuracy=91.9, loss=0.234]\n",
            "Epoch 41 Testing: 100%|██████████| 100/100 [00:04<00:00, 23.51batch/s, accuracy=88.4, loss=0.353]\n",
            "Epoch 42 Training: 100%|██████████| 391/391 [00:32<00:00, 11.91batch/s, accuracy=92, loss=0.231]\n",
            "Epoch 42 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.50batch/s, accuracy=88.8, loss=0.339]\n",
            "Epoch 43 Training: 100%|██████████| 391/391 [00:32<00:00, 11.99batch/s, accuracy=92, loss=0.23]\n",
            "Epoch 43 Testing: 100%|██████████| 100/100 [00:03<00:00, 28.10batch/s, accuracy=88.6, loss=0.369]\n",
            "Epoch 44 Training: 100%|██████████| 391/391 [00:32<00:00, 11.95batch/s, accuracy=92.2, loss=0.227]\n",
            "Epoch 44 Testing: 100%|██████████| 100/100 [00:03<00:00, 28.01batch/s, accuracy=88.4, loss=0.375]\n",
            "Epoch 45 Training: 100%|██████████| 391/391 [00:32<00:00, 12.18batch/s, accuracy=92.2, loss=0.226]\n",
            "Epoch 45 Testing: 100%|██████████| 100/100 [00:04<00:00, 21.99batch/s, accuracy=88.2, loss=0.384]\n",
            "Epoch 46 Training: 100%|██████████| 391/391 [00:32<00:00, 12.10batch/s, accuracy=92.4, loss=0.22]\n",
            "Epoch 46 Testing: 100%|██████████| 100/100 [00:04<00:00, 24.36batch/s, accuracy=89, loss=0.366]\n",
            "Epoch 47 Training: 100%|██████████| 391/391 [00:32<00:00, 12.13batch/s, accuracy=92.5, loss=0.218]\n",
            "Epoch 47 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.64batch/s, accuracy=87, loss=0.431]\n",
            "Epoch 48 Training: 100%|██████████| 391/391 [00:32<00:00, 11.93batch/s, accuracy=92.3, loss=0.222]\n",
            "Epoch 48 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.55batch/s, accuracy=88.7, loss=0.374]\n",
            "Epoch 49 Training: 100%|██████████| 391/391 [00:32<00:00, 12.12batch/s, accuracy=92.6, loss=0.215]\n",
            "Epoch 49 Testing: 100%|██████████| 100/100 [00:04<00:00, 23.57batch/s, accuracy=88.8, loss=0.352]\n",
            "Epoch 50 Training: 100%|██████████| 391/391 [00:32<00:00, 11.99batch/s, accuracy=92.7, loss=0.213]\n",
            "Epoch 50 Testing: 100%|██████████| 100/100 [00:04<00:00, 20.73batch/s, accuracy=89.2, loss=0.34]\n",
            "Epoch 51 Training: 100%|██████████| 391/391 [00:32<00:00, 11.99batch/s, accuracy=92.5, loss=0.216]\n",
            "Epoch 51 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.66batch/s, accuracy=87.9, loss=0.392]\n",
            "Epoch 52 Training: 100%|██████████| 391/391 [00:33<00:00, 11.85batch/s, accuracy=92.5, loss=0.214]\n",
            "Epoch 52 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.74batch/s, accuracy=89.3, loss=0.339]\n",
            "Epoch 53 Training: 100%|██████████| 391/391 [00:33<00:00, 11.77batch/s, accuracy=92.8, loss=0.209]\n",
            "Epoch 53 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.93batch/s, accuracy=88.7, loss=0.35]\n",
            "Epoch 54 Training: 100%|██████████| 391/391 [00:32<00:00, 12.03batch/s, accuracy=93, loss=0.206]\n",
            "Epoch 54 Testing: 100%|██████████| 100/100 [00:04<00:00, 22.84batch/s, accuracy=88.7, loss=0.366]\n",
            "Epoch 55 Training: 100%|██████████| 391/391 [00:32<00:00, 12.13batch/s, accuracy=93.1, loss=0.205]\n",
            "Epoch 55 Testing: 100%|██████████| 100/100 [00:04<00:00, 22.96batch/s, accuracy=87.7, loss=0.394]\n",
            "Epoch 56 Training: 100%|██████████| 391/391 [00:32<00:00, 12.11batch/s, accuracy=93, loss=0.204]\n",
            "Epoch 56 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.83batch/s, accuracy=89.2, loss=0.344]\n",
            "Epoch 57 Training: 100%|██████████| 391/391 [00:32<00:00, 12.02batch/s, accuracy=93.2, loss=0.199]\n",
            "Epoch 57 Testing: 100%|██████████| 100/100 [00:03<00:00, 28.16batch/s, accuracy=87.7, loss=0.389]\n",
            "Epoch 58 Training: 100%|██████████| 391/391 [00:32<00:00, 12.04batch/s, accuracy=93.2, loss=0.197]\n",
            "Epoch 58 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.53batch/s, accuracy=89.2, loss=0.341]\n",
            "Epoch 59 Training: 100%|██████████| 391/391 [00:31<00:00, 12.22batch/s, accuracy=93.3, loss=0.196]\n",
            "Epoch 59 Testing: 100%|██████████| 100/100 [00:04<00:00, 21.82batch/s, accuracy=88.5, loss=0.355]\n",
            "Epoch 60 Training: 100%|██████████| 391/391 [00:32<00:00, 12.16batch/s, accuracy=93.2, loss=0.198]\n",
            "Epoch 60 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.58batch/s, accuracy=89, loss=0.329]\n",
            "Epoch 61 Training: 100%|██████████| 391/391 [00:32<00:00, 12.01batch/s, accuracy=93.3, loss=0.196]\n",
            "Epoch 61 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.73batch/s, accuracy=88.9, loss=0.333]\n",
            "Epoch 62 Training: 100%|██████████| 391/391 [00:32<00:00, 11.93batch/s, accuracy=93.3, loss=0.193]\n",
            "Epoch 62 Testing: 100%|██████████| 100/100 [00:03<00:00, 28.01batch/s, accuracy=88.5, loss=0.365]\n",
            "Epoch 63 Training: 100%|██████████| 391/391 [00:32<00:00, 12.13batch/s, accuracy=93.5, loss=0.188]\n",
            "Epoch 63 Testing: 100%|██████████| 100/100 [00:04<00:00, 23.01batch/s, accuracy=89.2, loss=0.341]\n",
            "Epoch 64 Training: 100%|██████████| 391/391 [00:32<00:00, 12.11batch/s, accuracy=93.3, loss=0.192]\n",
            "Epoch 64 Testing: 100%|██████████| 100/100 [00:04<00:00, 24.46batch/s, accuracy=89.4, loss=0.343]\n",
            "Epoch 65 Training: 100%|██████████| 391/391 [00:32<00:00, 11.90batch/s, accuracy=93.4, loss=0.189]\n",
            "Epoch 65 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.48batch/s, accuracy=89.9, loss=0.321]\n",
            "Epoch 66 Training: 100%|██████████| 391/391 [00:33<00:00, 11.78batch/s, accuracy=93.6, loss=0.185]\n",
            "Epoch 66 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.08batch/s, accuracy=89.3, loss=0.336]\n",
            "Epoch 67 Training: 100%|██████████| 391/391 [00:32<00:00, 11.95batch/s, accuracy=93.7, loss=0.183]\n",
            "Epoch 67 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.30batch/s, accuracy=89.1, loss=0.363]\n",
            "Epoch 68 Training: 100%|██████████| 391/391 [00:32<00:00, 12.07batch/s, accuracy=93.8, loss=0.179]\n",
            "Epoch 68 Testing: 100%|██████████| 100/100 [00:04<00:00, 21.23batch/s, accuracy=89.5, loss=0.342]\n",
            "Epoch 69 Training: 100%|██████████| 391/391 [00:32<00:00, 12.16batch/s, accuracy=94, loss=0.177]\n",
            "Epoch 69 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.74batch/s, accuracy=89, loss=0.36]\n",
            "Epoch 70 Training: 100%|██████████| 391/391 [00:32<00:00, 11.86batch/s, accuracy=94, loss=0.173]\n",
            "Epoch 70 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.25batch/s, accuracy=88.8, loss=0.356]\n",
            "Epoch 71 Training: 100%|██████████| 391/391 [00:32<00:00, 11.88batch/s, accuracy=93.9, loss=0.178]\n",
            "Epoch 71 Testing: 100%|██████████| 100/100 [00:03<00:00, 28.13batch/s, accuracy=89.4, loss=0.352]\n",
            "Epoch 72 Training: 100%|██████████| 391/391 [00:32<00:00, 12.14batch/s, accuracy=94, loss=0.173]\n",
            "Epoch 72 Testing: 100%|██████████| 100/100 [00:04<00:00, 21.43batch/s, accuracy=89, loss=0.362]\n",
            "Epoch 73 Training: 100%|██████████| 391/391 [00:32<00:00, 12.12batch/s, accuracy=94, loss=0.173]\n",
            "Epoch 73 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.78batch/s, accuracy=89.4, loss=0.35]\n",
            "Epoch 74 Training: 100%|██████████| 391/391 [00:32<00:00, 11.88batch/s, accuracy=94.4, loss=0.165]\n",
            "Epoch 74 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.40batch/s, accuracy=89.6, loss=0.33]\n",
            "Epoch 75 Training: 100%|██████████| 391/391 [00:32<00:00, 11.90batch/s, accuracy=94.2, loss=0.167]\n",
            "Epoch 75 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.81batch/s, accuracy=89.3, loss=0.342]\n",
            "Epoch 76 Training: 100%|██████████| 391/391 [00:32<00:00, 12.12batch/s, accuracy=94.3, loss=0.163]\n",
            "Epoch 76 Testing: 100%|██████████| 100/100 [00:04<00:00, 24.12batch/s, accuracy=88.8, loss=0.378]\n",
            "Epoch 77 Training: 100%|██████████| 391/391 [00:32<00:00, 12.11batch/s, accuracy=94.6, loss=0.16]\n",
            "Epoch 77 Testing: 100%|██████████| 100/100 [00:04<00:00, 22.83batch/s, accuracy=89.1, loss=0.351]\n",
            "Epoch 78 Training: 100%|██████████| 391/391 [00:32<00:00, 12.17batch/s, accuracy=94.4, loss=0.159]\n",
            "Epoch 78 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.42batch/s, accuracy=89.8, loss=0.326]\n",
            "Epoch 79 Training: 100%|██████████| 391/391 [00:32<00:00, 11.91batch/s, accuracy=94.6, loss=0.157]\n",
            "Epoch 79 Testing: 100%|██████████| 100/100 [00:03<00:00, 27.13batch/s, accuracy=90.6, loss=0.31]\n",
            "Epoch 80 Training: 100%|██████████| 391/391 [00:32<00:00, 11.99batch/s, accuracy=94.7, loss=0.154]\n",
            "Epoch 80 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.71batch/s, accuracy=89, loss=0.37]\n",
            "Epoch 81 Training: 100%|██████████| 391/391 [00:33<00:00, 11.71batch/s, accuracy=94.8, loss=0.153]\n",
            "Epoch 81 Testing: 100%|██████████| 100/100 [00:05<00:00, 16.88batch/s, accuracy=88.5, loss=0.393]\n",
            "Epoch 82 Training: 100%|██████████| 391/391 [00:32<00:00, 12.14batch/s, accuracy=94.7, loss=0.155]\n",
            "Epoch 82 Testing: 100%|██████████| 100/100 [00:04<00:00, 23.37batch/s, accuracy=90.5, loss=0.304]\n",
            "Epoch 83 Training: 100%|██████████| 391/391 [00:32<00:00, 12.04batch/s, accuracy=94.7, loss=0.153]\n",
            "Epoch 83 Testing: 100%|██████████| 100/100 [00:04<00:00, 24.70batch/s, accuracy=89.7, loss=0.357]\n",
            "Epoch 84 Training: 100%|██████████| 391/391 [00:33<00:00, 11.80batch/s, accuracy=94.9, loss=0.147]\n",
            "Epoch 84 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.82batch/s, accuracy=90.4, loss=0.321]\n",
            "Epoch 85 Training: 100%|██████████| 391/391 [00:33<00:00, 11.66batch/s, accuracy=95, loss=0.147]\n",
            "Epoch 85 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.44batch/s, accuracy=88.8, loss=0.386]\n",
            "Epoch 86 Training: 100%|██████████| 391/391 [00:33<00:00, 11.77batch/s, accuracy=95.2, loss=0.142]\n",
            "Epoch 86 Testing: 100%|██████████| 100/100 [00:04<00:00, 22.25batch/s, accuracy=90, loss=0.335]\n",
            "Epoch 87 Training: 100%|██████████| 391/391 [00:32<00:00, 12.00batch/s, accuracy=95.1, loss=0.142]\n",
            "Epoch 87 Testing: 100%|██████████| 100/100 [00:04<00:00, 22.57batch/s, accuracy=90.8, loss=0.316]\n",
            "Epoch 88 Training: 100%|██████████| 391/391 [00:33<00:00, 11.73batch/s, accuracy=95.1, loss=0.143]\n",
            "Epoch 88 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.04batch/s, accuracy=90, loss=0.339]\n",
            "Epoch 89 Training: 100%|██████████| 391/391 [00:33<00:00, 11.63batch/s, accuracy=95.2, loss=0.141]\n",
            "Epoch 89 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.60batch/s, accuracy=90.9, loss=0.3]\n",
            "Epoch 90 Training: 100%|██████████| 391/391 [00:33<00:00, 11.64batch/s, accuracy=95.6, loss=0.13]\n",
            "Epoch 90 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.98batch/s, accuracy=90.5, loss=0.315]\n",
            "Epoch 91 Training: 100%|██████████| 391/391 [00:33<00:00, 11.79batch/s, accuracy=95.4, loss=0.133]\n",
            "Epoch 91 Testing: 100%|██████████| 100/100 [00:04<00:00, 22.41batch/s, accuracy=89.9, loss=0.333]\n",
            "Epoch 92 Training: 100%|██████████| 391/391 [00:33<00:00, 11.64batch/s, accuracy=95.4, loss=0.133]\n",
            "Epoch 92 Testing: 100%|██████████| 100/100 [00:04<00:00, 20.79batch/s, accuracy=90.2, loss=0.326]\n",
            "Epoch 93 Training: 100%|██████████| 391/391 [00:32<00:00, 11.95batch/s, accuracy=95.5, loss=0.13]\n",
            "Epoch 93 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.31batch/s, accuracy=89.9, loss=0.351]\n",
            "Epoch 94 Training: 100%|██████████| 391/391 [00:32<00:00, 11.86batch/s, accuracy=95.8, loss=0.122]\n",
            "Epoch 94 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.38batch/s, accuracy=89.4, loss=0.36]\n",
            "Epoch 95 Training: 100%|██████████| 391/391 [00:33<00:00, 11.77batch/s, accuracy=95.6, loss=0.127]\n",
            "Epoch 95 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.26batch/s, accuracy=89.8, loss=0.346]\n",
            "Epoch 96 Training: 100%|██████████| 391/391 [00:33<00:00, 11.81batch/s, accuracy=95.9, loss=0.122]\n",
            "Epoch 96 Testing: 100%|██████████| 100/100 [00:04<00:00, 23.73batch/s, accuracy=89.9, loss=0.356]\n",
            "Epoch 97 Training: 100%|██████████| 391/391 [00:32<00:00, 11.88batch/s, accuracy=95.8, loss=0.122]\n",
            "Epoch 97 Testing: 100%|██████████| 100/100 [00:04<00:00, 20.56batch/s, accuracy=90.3, loss=0.336]\n",
            "Epoch 98 Training: 100%|██████████| 391/391 [00:32<00:00, 11.90batch/s, accuracy=95.9, loss=0.118]\n",
            "Epoch 98 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.81batch/s, accuracy=90.3, loss=0.339]\n",
            "Epoch 99 Training: 100%|██████████| 391/391 [00:33<00:00, 11.56batch/s, accuracy=95.8, loss=0.124]\n",
            "Epoch 99 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.57batch/s, accuracy=90.5, loss=0.322]\n",
            "Epoch 100 Training: 100%|██████████| 391/391 [00:33<00:00, 11.58batch/s, accuracy=96, loss=0.115]\n",
            "Epoch 100 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.61batch/s, accuracy=90.3, loss=0.34]\n",
            "Epoch 101 Training: 100%|██████████| 391/391 [00:33<00:00, 11.64batch/s, accuracy=96.2, loss=0.112]\n",
            "Epoch 101 Testing: 100%|██████████| 100/100 [00:04<00:00, 24.81batch/s, accuracy=90.7, loss=0.328]\n",
            "Epoch 102 Training: 100%|██████████| 391/391 [00:32<00:00, 11.89batch/s, accuracy=96.3, loss=0.11]\n",
            "Epoch 102 Testing: 100%|██████████| 100/100 [00:04<00:00, 20.15batch/s, accuracy=90.2, loss=0.341]\n",
            "Epoch 103 Training: 100%|██████████| 391/391 [00:32<00:00, 11.85batch/s, accuracy=96.3, loss=0.107]\n",
            "Epoch 103 Testing: 100%|██████████| 100/100 [00:04<00:00, 23.53batch/s, accuracy=90, loss=0.35]\n",
            "Epoch 104 Training: 100%|██████████| 391/391 [00:33<00:00, 11.79batch/s, accuracy=96.3, loss=0.108]\n",
            "Epoch 104 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.02batch/s, accuracy=90.3, loss=0.337]\n",
            "Epoch 105 Training: 100%|██████████| 391/391 [00:33<00:00, 11.61batch/s, accuracy=96.3, loss=0.104]\n",
            "Epoch 105 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.49batch/s, accuracy=90.2, loss=0.344]\n",
            "Epoch 106 Training: 100%|██████████| 391/391 [00:33<00:00, 11.62batch/s, accuracy=96.5, loss=0.102]\n",
            "Epoch 106 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.93batch/s, accuracy=90.4, loss=0.329]\n",
            "Epoch 107 Training: 100%|██████████| 391/391 [00:33<00:00, 11.75batch/s, accuracy=96.6, loss=0.102]\n",
            "Epoch 107 Testing: 100%|██████████| 100/100 [00:05<00:00, 19.67batch/s, accuracy=90.6, loss=0.33]\n",
            "Epoch 108 Training: 100%|██████████| 391/391 [00:33<00:00, 11.80batch/s, accuracy=96.5, loss=0.102]\n",
            "Epoch 108 Testing: 100%|██████████| 100/100 [00:04<00:00, 22.19batch/s, accuracy=90.5, loss=0.339]\n",
            "Epoch 109 Training: 100%|██████████| 391/391 [00:33<00:00, 11.72batch/s, accuracy=96.7, loss=0.0972]\n",
            "Epoch 109 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.42batch/s, accuracy=90.3, loss=0.338]\n",
            "Epoch 110 Training: 100%|██████████| 391/391 [00:33<00:00, 11.59batch/s, accuracy=96.6, loss=0.0979]\n",
            "Epoch 110 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.40batch/s, accuracy=90.4, loss=0.337]\n",
            "Epoch 111 Training: 100%|██████████| 391/391 [00:33<00:00, 11.71batch/s, accuracy=96.9, loss=0.0925]\n",
            "Epoch 111 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.25batch/s, accuracy=90.7, loss=0.325]\n",
            "Epoch 112 Training: 100%|██████████| 391/391 [00:32<00:00, 11.92batch/s, accuracy=97.1, loss=0.0868]\n",
            "Epoch 112 Testing: 100%|██████████| 100/100 [00:04<00:00, 21.63batch/s, accuracy=91.1, loss=0.328]\n",
            "Epoch 113 Training: 100%|██████████| 391/391 [00:32<00:00, 11.90batch/s, accuracy=97.1, loss=0.0878]\n",
            "Epoch 113 Testing: 100%|██████████| 100/100 [00:04<00:00, 21.61batch/s, accuracy=90.8, loss=0.331]\n",
            "Epoch 114 Training: 100%|██████████| 391/391 [00:33<00:00, 11.79batch/s, accuracy=97, loss=0.089]\n",
            "Epoch 114 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.69batch/s, accuracy=90.8, loss=0.321]\n",
            "Epoch 115 Training: 100%|██████████| 391/391 [00:33<00:00, 11.73batch/s, accuracy=97.2, loss=0.0826]\n",
            "Epoch 115 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.83batch/s, accuracy=90, loss=0.359]\n",
            "Epoch 116 Training: 100%|██████████| 391/391 [00:33<00:00, 11.64batch/s, accuracy=97.3, loss=0.0804]\n",
            "Epoch 116 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.02batch/s, accuracy=90.7, loss=0.335]\n",
            "Epoch 117 Training: 100%|██████████| 391/391 [00:32<00:00, 11.90batch/s, accuracy=97.2, loss=0.0829]\n",
            "Epoch 117 Testing: 100%|██████████| 100/100 [00:04<00:00, 21.59batch/s, accuracy=90.7, loss=0.331]\n",
            "Epoch 118 Training: 100%|██████████| 391/391 [00:32<00:00, 11.88batch/s, accuracy=97.3, loss=0.0813]\n",
            "Epoch 118 Testing: 100%|██████████| 100/100 [00:04<00:00, 22.55batch/s, accuracy=90.7, loss=0.334]\n",
            "Epoch 119 Training: 100%|██████████| 391/391 [00:32<00:00, 11.91batch/s, accuracy=97.3, loss=0.0783]\n",
            "Epoch 119 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.39batch/s, accuracy=91.3, loss=0.311]\n",
            "Epoch 120 Training: 100%|██████████| 391/391 [00:33<00:00, 11.67batch/s, accuracy=97.4, loss=0.0754]\n",
            "Epoch 120 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.76batch/s, accuracy=91.4, loss=0.312]\n",
            "Epoch 121 Training: 100%|██████████| 391/391 [00:33<00:00, 11.82batch/s, accuracy=97.6, loss=0.0717]\n",
            "Epoch 121 Testing: 100%|██████████| 100/100 [00:04<00:00, 23.98batch/s, accuracy=91.1, loss=0.327]\n",
            "Epoch 122 Training: 100%|██████████| 391/391 [00:33<00:00, 11.84batch/s, accuracy=97.6, loss=0.0735]\n",
            "Epoch 122 Testing: 100%|██████████| 100/100 [00:04<00:00, 20.04batch/s, accuracy=91, loss=0.338]\n",
            "Epoch 123 Training: 100%|██████████| 391/391 [00:33<00:00, 11.79batch/s, accuracy=97.8, loss=0.0678]\n",
            "Epoch 123 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.46batch/s, accuracy=91.5, loss=0.314]\n",
            "Epoch 124 Training: 100%|██████████| 391/391 [00:33<00:00, 11.62batch/s, accuracy=97.8, loss=0.0671]\n",
            "Epoch 124 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.25batch/s, accuracy=91.3, loss=0.318]\n",
            "Epoch 125 Training: 100%|██████████| 391/391 [00:33<00:00, 11.66batch/s, accuracy=97.8, loss=0.0665]\n",
            "Epoch 125 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.24batch/s, accuracy=91.2, loss=0.33]\n",
            "Epoch 126 Training: 100%|██████████| 391/391 [00:32<00:00, 11.94batch/s, accuracy=97.8, loss=0.0673]\n",
            "Epoch 126 Testing: 100%|██████████| 100/100 [00:04<00:00, 20.34batch/s, accuracy=91.4, loss=0.308]\n",
            "Epoch 127 Training: 100%|██████████| 391/391 [00:32<00:00, 11.90batch/s, accuracy=98, loss=0.0614]\n",
            "Epoch 127 Testing: 100%|██████████| 100/100 [00:04<00:00, 23.03batch/s, accuracy=91, loss=0.345]\n",
            "Epoch 128 Training: 100%|██████████| 391/391 [00:33<00:00, 11.77batch/s, accuracy=98, loss=0.0618]\n",
            "Epoch 128 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.13batch/s, accuracy=91.2, loss=0.334]\n",
            "Epoch 129 Training: 100%|██████████| 391/391 [00:33<00:00, 11.61batch/s, accuracy=98.1, loss=0.0568]\n",
            "Epoch 129 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.41batch/s, accuracy=91.4, loss=0.325]\n",
            "Epoch 130 Training: 100%|██████████| 391/391 [00:33<00:00, 11.61batch/s, accuracy=98, loss=0.0585]\n",
            "Epoch 130 Testing: 100%|██████████| 100/100 [00:04<00:00, 24.39batch/s, accuracy=91.4, loss=0.315]\n",
            "Epoch 131 Training: 100%|██████████| 391/391 [00:33<00:00, 11.72batch/s, accuracy=98.2, loss=0.0566]\n",
            "Epoch 131 Testing: 100%|██████████| 100/100 [00:05<00:00, 19.68batch/s, accuracy=91.1, loss=0.34]\n",
            "Epoch 132 Training: 100%|██████████| 391/391 [00:33<00:00, 11.78batch/s, accuracy=98.3, loss=0.0537]\n",
            "Epoch 132 Testing: 100%|██████████| 100/100 [00:04<00:00, 22.34batch/s, accuracy=91.1, loss=0.329]\n",
            "Epoch 133 Training: 100%|██████████| 391/391 [00:33<00:00, 11.59batch/s, accuracy=98.4, loss=0.0509]\n",
            "Epoch 133 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.79batch/s, accuracy=91.3, loss=0.328]\n",
            "Epoch 134 Training: 100%|██████████| 391/391 [00:33<00:00, 11.70batch/s, accuracy=98.3, loss=0.0517]\n",
            "Epoch 134 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.77batch/s, accuracy=91.5, loss=0.329]\n",
            "Epoch 135 Training: 100%|██████████| 391/391 [00:33<00:00, 11.80batch/s, accuracy=98.4, loss=0.0491]\n",
            "Epoch 135 Testing: 100%|██████████| 100/100 [00:04<00:00, 23.99batch/s, accuracy=91.7, loss=0.314]\n",
            "Epoch 136 Training: 100%|██████████| 391/391 [00:32<00:00, 11.88batch/s, accuracy=98.6, loss=0.0463]\n",
            "Epoch 136 Testing: 100%|██████████| 100/100 [00:05<00:00, 19.70batch/s, accuracy=91.8, loss=0.314]\n",
            "Epoch 137 Training: 100%|██████████| 391/391 [00:32<00:00, 11.90batch/s, accuracy=98.6, loss=0.0449]\n",
            "Epoch 137 Testing: 100%|██████████| 100/100 [00:04<00:00, 23.41batch/s, accuracy=91.8, loss=0.312]\n",
            "Epoch 138 Training: 100%|██████████| 391/391 [00:33<00:00, 11.70batch/s, accuracy=98.6, loss=0.0447]\n",
            "Epoch 138 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.39batch/s, accuracy=91.8, loss=0.309]\n",
            "Epoch 139 Training: 100%|██████████| 391/391 [00:33<00:00, 11.59batch/s, accuracy=98.6, loss=0.0435]\n",
            "Epoch 139 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.88batch/s, accuracy=91.6, loss=0.333]\n",
            "Epoch 140 Training: 100%|██████████| 391/391 [00:33<00:00, 11.77batch/s, accuracy=98.7, loss=0.0426]\n",
            "Epoch 140 Testing: 100%|██████████| 100/100 [00:04<00:00, 22.58batch/s, accuracy=91.8, loss=0.316]\n",
            "Epoch 141 Training: 100%|██████████| 391/391 [00:32<00:00, 11.86batch/s, accuracy=98.8, loss=0.0392]\n",
            "Epoch 141 Testing: 100%|██████████| 100/100 [00:05<00:00, 19.82batch/s, accuracy=91.4, loss=0.33]\n",
            "Epoch 142 Training: 100%|██████████| 391/391 [00:33<00:00, 11.83batch/s, accuracy=98.8, loss=0.0374]\n",
            "Epoch 142 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.18batch/s, accuracy=91.6, loss=0.331]\n",
            "Epoch 143 Training: 100%|██████████| 391/391 [00:33<00:00, 11.67batch/s, accuracy=98.8, loss=0.0384]\n",
            "Epoch 143 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.07batch/s, accuracy=91.6, loss=0.329]\n",
            "Epoch 144 Training: 100%|██████████| 391/391 [00:33<00:00, 11.60batch/s, accuracy=99, loss=0.0348]\n",
            "Epoch 144 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.89batch/s, accuracy=91.6, loss=0.325]\n",
            "Epoch 145 Training: 100%|██████████| 391/391 [00:33<00:00, 11.84batch/s, accuracy=98.9, loss=0.0359]\n",
            "Epoch 145 Testing: 100%|██████████| 100/100 [00:04<00:00, 21.88batch/s, accuracy=91.6, loss=0.325]\n",
            "Epoch 146 Training: 100%|██████████| 391/391 [00:33<00:00, 11.80batch/s, accuracy=99, loss=0.0348]\n",
            "Epoch 146 Testing: 100%|██████████| 100/100 [00:04<00:00, 20.76batch/s, accuracy=91.7, loss=0.317]\n",
            "Epoch 147 Training: 100%|██████████| 391/391 [00:33<00:00, 11.73batch/s, accuracy=99.1, loss=0.0313]\n",
            "Epoch 147 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.84batch/s, accuracy=91.6, loss=0.315]\n",
            "Epoch 148 Training: 100%|██████████| 391/391 [00:33<00:00, 11.59batch/s, accuracy=99.1, loss=0.0316]\n",
            "Epoch 148 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.18batch/s, accuracy=91.5, loss=0.328]\n",
            "Epoch 149 Training: 100%|██████████| 391/391 [00:33<00:00, 11.52batch/s, accuracy=99.2, loss=0.029]\n",
            "Epoch 149 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.26batch/s, accuracy=91.5, loss=0.33]\n",
            "Epoch 150 Training: 100%|██████████| 391/391 [00:33<00:00, 11.78batch/s, accuracy=99.2, loss=0.0285]\n",
            "Epoch 150 Testing: 100%|██████████| 100/100 [00:04<00:00, 20.40batch/s, accuracy=92, loss=0.31]\n",
            "Epoch 151 Training: 100%|██████████| 391/391 [00:32<00:00, 11.87batch/s, accuracy=99.3, loss=0.0269]\n",
            "Epoch 151 Testing: 100%|██████████| 100/100 [00:04<00:00, 22.01batch/s, accuracy=91.8, loss=0.308]\n",
            "Epoch 152 Training: 100%|██████████| 391/391 [00:33<00:00, 11.66batch/s, accuracy=99.3, loss=0.0262]\n",
            "Epoch 152 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.34batch/s, accuracy=91.7, loss=0.32]\n",
            "Epoch 153 Training: 100%|██████████| 391/391 [00:33<00:00, 11.60batch/s, accuracy=99.4, loss=0.024]\n",
            "Epoch 153 Testing: 100%|██████████| 100/100 [00:04<00:00, 24.49batch/s, accuracy=92.2, loss=0.298]\n",
            "Epoch 154 Training: 100%|██████████| 391/391 [00:33<00:00, 11.54batch/s, accuracy=99.4, loss=0.0238]\n",
            "Epoch 154 Testing: 100%|██████████| 100/100 [00:04<00:00, 23.88batch/s, accuracy=92.3, loss=0.3]\n",
            "Epoch 155 Training: 100%|██████████| 391/391 [00:33<00:00, 11.67batch/s, accuracy=99.3, loss=0.0253]\n",
            "Epoch 155 Testing: 100%|██████████| 100/100 [00:05<00:00, 19.92batch/s, accuracy=92.2, loss=0.3]\n",
            "Epoch 156 Training: 100%|██████████| 391/391 [00:33<00:00, 11.84batch/s, accuracy=99.5, loss=0.0213]\n",
            "Epoch 156 Testing: 100%|██████████| 100/100 [00:04<00:00, 23.17batch/s, accuracy=92.1, loss=0.306]\n",
            "Epoch 157 Training: 100%|██████████| 391/391 [00:33<00:00, 11.58batch/s, accuracy=99.5, loss=0.0206]\n",
            "Epoch 157 Testing: 100%|██████████| 100/100 [00:04<00:00, 24.79batch/s, accuracy=92.1, loss=0.31]\n",
            "Epoch 158 Training: 100%|██████████| 391/391 [00:33<00:00, 11.60batch/s, accuracy=99.5, loss=0.02]\n",
            "Epoch 158 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.09batch/s, accuracy=92.1, loss=0.305]\n",
            "Epoch 159 Training: 100%|██████████| 391/391 [00:33<00:00, 11.79batch/s, accuracy=99.5, loss=0.0197]\n",
            "Epoch 159 Testing: 100%|██████████| 100/100 [00:04<00:00, 20.65batch/s, accuracy=92.2, loss=0.305]\n",
            "Epoch 160 Training: 100%|██████████| 391/391 [00:33<00:00, 11.85batch/s, accuracy=99.6, loss=0.0177]\n",
            "Epoch 160 Testing: 100%|██████████| 100/100 [00:04<00:00, 22.38batch/s, accuracy=92.2, loss=0.299]\n",
            "Epoch 161 Training: 100%|██████████| 391/391 [00:34<00:00, 11.40batch/s, accuracy=99.6, loss=0.0169]\n",
            "Epoch 161 Testing: 100%|██████████| 100/100 [00:04<00:00, 24.10batch/s, accuracy=92.2, loss=0.304]\n",
            "Epoch 162 Training: 100%|██████████| 391/391 [00:34<00:00, 11.42batch/s, accuracy=99.6, loss=0.0174]\n",
            "Epoch 162 Testing: 100%|██████████| 100/100 [00:04<00:00, 24.75batch/s, accuracy=92.3, loss=0.3]\n",
            "Epoch 163 Training: 100%|██████████| 391/391 [00:33<00:00, 11.52batch/s, accuracy=99.6, loss=0.0173]\n",
            "Epoch 163 Testing: 100%|██████████| 100/100 [00:04<00:00, 23.26batch/s, accuracy=92.2, loss=0.302]\n",
            "Epoch 164 Training: 100%|██████████| 391/391 [00:33<00:00, 11.79batch/s, accuracy=99.6, loss=0.0159]\n",
            "Epoch 164 Testing: 100%|██████████| 100/100 [00:05<00:00, 19.89batch/s, accuracy=92.2, loss=0.305]\n",
            "Epoch 165 Training: 100%|██████████| 391/391 [00:32<00:00, 11.91batch/s, accuracy=99.7, loss=0.0155]\n",
            "Epoch 165 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.40batch/s, accuracy=92.3, loss=0.304]\n",
            "Epoch 166 Training: 100%|██████████| 391/391 [00:33<00:00, 11.74batch/s, accuracy=99.7, loss=0.0145]\n",
            "Epoch 166 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.15batch/s, accuracy=92.5, loss=0.298]\n",
            "Epoch 167 Training: 100%|██████████| 391/391 [00:32<00:00, 11.94batch/s, accuracy=99.7, loss=0.0139]\n",
            "Epoch 167 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.34batch/s, accuracy=92.4, loss=0.292]\n",
            "Epoch 168 Training: 100%|██████████| 391/391 [00:32<00:00, 11.96batch/s, accuracy=99.8, loss=0.0129]\n",
            "Epoch 168 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.24batch/s, accuracy=92.5, loss=0.295]\n",
            "Epoch 169 Training: 100%|██████████| 391/391 [00:32<00:00, 11.98batch/s, accuracy=99.8, loss=0.0129]\n",
            "Epoch 169 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.91batch/s, accuracy=92.4, loss=0.298]\n",
            "Epoch 170 Training: 100%|██████████| 391/391 [00:32<00:00, 11.90batch/s, accuracy=99.7, loss=0.0131]\n",
            "Epoch 170 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.48batch/s, accuracy=92.7, loss=0.288]\n",
            "Epoch 171 Training: 100%|██████████| 391/391 [00:32<00:00, 11.89batch/s, accuracy=99.8, loss=0.0125]\n",
            "Epoch 171 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.22batch/s, accuracy=92.6, loss=0.289]\n",
            "Epoch 172 Training: 100%|██████████| 391/391 [00:32<00:00, 12.04batch/s, accuracy=99.8, loss=0.011]\n",
            "Epoch 172 Testing: 100%|██████████| 100/100 [00:04<00:00, 24.04batch/s, accuracy=92.6, loss=0.293]\n",
            "Epoch 173 Training: 100%|██████████| 391/391 [00:32<00:00, 12.09batch/s, accuracy=99.8, loss=0.0113]\n",
            "Epoch 173 Testing: 100%|██████████| 100/100 [00:04<00:00, 22.05batch/s, accuracy=92.5, loss=0.288]\n",
            "Epoch 174 Training: 100%|██████████| 391/391 [00:32<00:00, 11.93batch/s, accuracy=99.8, loss=0.0108]\n",
            "Epoch 174 Testing: 100%|██████████| 100/100 [00:04<00:00, 22.66batch/s, accuracy=92.8, loss=0.28]\n",
            "Epoch 175 Training: 100%|██████████| 391/391 [00:32<00:00, 11.97batch/s, accuracy=99.8, loss=0.0106]\n",
            "Epoch 175 Testing: 100%|██████████| 100/100 [00:04<00:00, 21.98batch/s, accuracy=92.8, loss=0.281]\n",
            "Epoch 176 Training: 100%|██████████| 391/391 [00:32<00:00, 12.16batch/s, accuracy=99.9, loss=0.00973]\n",
            "Epoch 176 Testing: 100%|██████████| 100/100 [00:04<00:00, 21.78batch/s, accuracy=92.7, loss=0.285]\n",
            "Epoch 177 Training: 100%|██████████| 391/391 [00:32<00:00, 12.06batch/s, accuracy=99.9, loss=0.00965]\n",
            "Epoch 177 Testing: 100%|██████████| 100/100 [00:04<00:00, 21.28batch/s, accuracy=92.7, loss=0.278]\n",
            "Epoch 178 Training: 100%|██████████| 391/391 [00:32<00:00, 12.06batch/s, accuracy=99.9, loss=0.00951]\n",
            "Epoch 178 Testing: 100%|██████████| 100/100 [00:04<00:00, 21.95batch/s, accuracy=92.7, loss=0.284]\n",
            "Epoch 179 Training: 100%|██████████| 391/391 [00:32<00:00, 12.00batch/s, accuracy=99.9, loss=0.00885]\n",
            "Epoch 179 Testing: 100%|██████████| 100/100 [00:04<00:00, 22.61batch/s, accuracy=92.7, loss=0.282]\n",
            "Epoch 180 Training: 100%|██████████| 391/391 [00:32<00:00, 11.86batch/s, accuracy=99.9, loss=0.00874]\n",
            "Epoch 180 Testing: 100%|██████████| 100/100 [00:04<00:00, 23.27batch/s, accuracy=92.8, loss=0.278]\n",
            "Epoch 181 Training: 100%|██████████| 391/391 [00:32<00:00, 11.97batch/s, accuracy=99.9, loss=0.00872]\n",
            "Epoch 181 Testing: 100%|██████████| 100/100 [00:04<00:00, 24.07batch/s, accuracy=92.5, loss=0.285]\n",
            "Epoch 182 Training: 100%|██████████| 391/391 [00:32<00:00, 11.97batch/s, accuracy=99.9, loss=0.00854]\n",
            "Epoch 182 Testing: 100%|██████████| 100/100 [00:03<00:00, 26.21batch/s, accuracy=92.7, loss=0.284]\n",
            "Epoch 183 Training: 100%|██████████| 391/391 [00:32<00:00, 11.89batch/s, accuracy=99.9, loss=0.00838]\n",
            "Epoch 183 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.64batch/s, accuracy=92.8, loss=0.283]\n",
            "Epoch 184 Training: 100%|██████████| 391/391 [00:32<00:00, 11.95batch/s, accuracy=99.9, loss=0.00798]\n",
            "Epoch 184 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.96batch/s, accuracy=92.7, loss=0.278]\n",
            "Epoch 185 Training: 100%|██████████| 391/391 [00:32<00:00, 11.90batch/s, accuracy=99.9, loss=0.00772]\n",
            "Epoch 185 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.23batch/s, accuracy=92.9, loss=0.281]\n",
            "Epoch 186 Training: 100%|██████████| 391/391 [00:32<00:00, 11.85batch/s, accuracy=99.9, loss=0.00826]\n",
            "Epoch 186 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.18batch/s, accuracy=92.8, loss=0.28]\n",
            "Epoch 187 Training: 100%|██████████| 391/391 [00:33<00:00, 11.77batch/s, accuracy=99.9, loss=0.00759]\n",
            "Epoch 187 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.19batch/s, accuracy=92.8, loss=0.279]\n",
            "Epoch 188 Training: 100%|██████████| 391/391 [00:33<00:00, 11.79batch/s, accuracy=99.9, loss=0.00768]\n",
            "Epoch 188 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.61batch/s, accuracy=92.8, loss=0.278]\n",
            "Epoch 189 Training: 100%|██████████| 391/391 [00:32<00:00, 11.90batch/s, accuracy=99.9, loss=0.00753]\n",
            "Epoch 189 Testing: 100%|██████████| 100/100 [00:03<00:00, 25.87batch/s, accuracy=93, loss=0.278]\n",
            "Epoch 190 Training: 100%|██████████| 391/391 [00:32<00:00, 11.98batch/s, accuracy=100, loss=0.00691]\n",
            "Epoch 190 Testing: 100%|██████████| 100/100 [00:04<00:00, 24.87batch/s, accuracy=92.9, loss=0.279]\n",
            "Epoch 191 Training: 100%|██████████| 391/391 [00:32<00:00, 11.95batch/s, accuracy=99.9, loss=0.00715]\n",
            "Epoch 191 Testing: 100%|██████████| 100/100 [00:04<00:00, 23.73batch/s, accuracy=92.9, loss=0.278]\n",
            "Epoch 192 Training: 100%|██████████| 391/391 [00:32<00:00, 11.91batch/s, accuracy=99.9, loss=0.00702]\n",
            "Epoch 192 Testing: 100%|██████████| 100/100 [00:04<00:00, 22.84batch/s, accuracy=92.7, loss=0.276]\n",
            "Epoch 193 Training: 100%|██████████| 391/391 [00:32<00:00, 11.99batch/s, accuracy=99.9, loss=0.00711]\n",
            "Epoch 193 Testing: 100%|██████████| 100/100 [00:04<00:00, 22.62batch/s, accuracy=92.8, loss=0.277]\n",
            "Epoch 194 Training: 100%|██████████| 391/391 [00:32<00:00, 11.97batch/s, accuracy=100, loss=0.00683]\n",
            "Epoch 194 Testing: 100%|██████████| 100/100 [00:04<00:00, 20.96batch/s, accuracy=93, loss=0.277]\n",
            "Epoch 195 Training: 100%|██████████| 391/391 [00:32<00:00, 11.91batch/s, accuracy=99.9, loss=0.00716]\n",
            "Epoch 195 Testing: 100%|██████████| 100/100 [00:04<00:00, 20.12batch/s, accuracy=92.8, loss=0.276]\n",
            "Epoch 196 Training: 100%|██████████| 391/391 [00:33<00:00, 11.68batch/s, accuracy=99.9, loss=0.00669]\n",
            "Epoch 196 Testing: 100%|██████████| 100/100 [00:04<00:00, 20.12batch/s, accuracy=92.9, loss=0.276]\n",
            "Epoch 197 Training: 100%|██████████| 391/391 [00:33<00:00, 11.84batch/s, accuracy=99.9, loss=0.00729]\n",
            "Epoch 197 Testing: 100%|██████████| 100/100 [00:04<00:00, 20.81batch/s, accuracy=92.9, loss=0.276]\n",
            "Epoch 198 Training: 100%|██████████| 391/391 [00:33<00:00, 11.83batch/s, accuracy=100, loss=0.00671]\n",
            "Epoch 198 Testing: 100%|██████████| 100/100 [00:04<00:00, 22.57batch/s, accuracy=92.9, loss=0.276]\n",
            "Epoch 199 Training: 100%|██████████| 391/391 [00:33<00:00, 11.79batch/s, accuracy=99.9, loss=0.00677]\n",
            "Epoch 199 Testing: 100%|██████████| 100/100 [00:04<00:00, 21.91batch/s, accuracy=93, loss=0.276]\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(start_epoch, start_epoch+200):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    scheduler.step()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}